# gensim模块基础应用学习

- wiki_chinese_preprocessed.simplied.txt
训练数据,从别人那获取的,是已经做好分词的维基百科简体中文训练数据
- wiki_chinese_preprocessed.simplied_1.txt
截取训练数据的0到100篇文章
- wiki_chinese_preprocessed.simplied_2.txt
截取训练数据的100到200篇文章

数据来源: http://pan.baidu.com/s/1jHZCvvo

中文分词工具: [结巴分词(python)](https://github.com/fxsjy/jieba)

